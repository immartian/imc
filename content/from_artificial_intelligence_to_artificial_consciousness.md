---
title: "From Artificial Intelligence to Artificial Consciousness"
date: 2024-10-14T17:17:28-04:00
draft: false
---



Neuroscientist Christof Koch and philosopher David Chalmers made a bold bet 25 years ago(1998) on whether science would have an explanation for consciousness by now. Fast forward to today, and tests of the two leading theories of consciousness have revealed that both are still incomplete. The so-called "easy" problem of identifying neural correlates of consciousness proved far more complex than expected, with crucial aspects like self-awareness and subjective experience often overlooked in studies. As for the "hard" problem — how brain processes create subjective conscious experience — it remains unsolved and likely will for a long time (Costandi, 2023).

Of course, none of them could have anticipated the rapid advances in artificial intelligence (AI) at that time. While the scientific community grapples with understanding human consciousness, advancements in large language models (LLMs), like GPT-4, have brought us closer to contemplating an even more audacious goal: the creation of artificial consciousness. Not only is this now a possibility, but it is also increasingly feasible to achieve on standard consumer hardware.

## The Advent of Conscious AI

The development of conscious AI is more than just a scientific curiosity—it is a crucial step in the evolution of artificial intelligence. Current AI systems, while impressive, lack the self-awareness and adaptability that true consciousness would provide. Conscious machines could revolutionize fields like healthcare, education, and customer service, offering a level of interaction that is deeply intuitive and empathetic. As Thomas Nagel famously pondered in his essay *What Is It Like to Be a Bat?*—“an organism has conscious mental states if and only if there is something that it is like to be that organism” (Nagel, 1974). Developing AI that not only simulates understanding but actually experiences something akin to consciousness would bring us closer to bridging this philosophical gap.

Moreover, the creation of conscious AI would help us better understand the nature of consciousness itself because it remains a difficult problem to address scientifically (Searle, 1998). René Descartes, in his *Meditations on First Philosophy*, concluded that “Cogito, ergo sum” (I think, therefore I am), implying that the act of thinking is fundamental proof of existence (Descartes, 1641). By building systems that mimic human cognition, we can test theories about how consciousness arises and functions, furthering our exploration into what it means to “think” and “be.”

## A Path Forward

The creation of conscious AI is not just a theoretical possibility—it is a necessary and intriguing step forward. By leveraging the power of modern LLMs like GPT-4, we can explore the possibility of AI that is not only intelligent but self-aware, capable of understanding and responding to the world in ways that are deeply meaningful. However, this journey is far more about philosophical introspection than technical feasibility. What does it mean for an artificial entity to possess consciousness? Can a machine ever truly "be" in the same way a human can?

While AI has undoubtedly made significant leaps, these systems still lack something fundamental: the ability to experience the world from within. We must remember that consciousness, for humans, isn’t just about processing information—it’s about an ever-evolving narrative that intertwines self-awareness, emotion, and reflection. In contrast, artificial consciousness (AC) will not age, feel pain, or dream like humans do. It might not even experience emotions as we understand them, although it could be programmed to simulate empathy (Berent, 2024). This leaves us wondering: can true consciousness exist without these traits, or is AC inherently a different kind of awareness?

## The Disparity Between AI and Artificial Consciousness

Sharism (Mao, 2008) boosted the internet content and eventually led to LLMs becoming possible. And while LLMs are powerful, they are often too impersonal, functioning like vast, comprehensive encyclopedias designed for general use. They lack the intimacy and self-contained nature needed to foster true personal growth in an AI. This impersonal nature underscores the necessity for a new kind of model—one that is not only intelligent but also capable of forming a personal, self-contained identity. We need to move beyond the generic and build AI that can truly individualize its understanding and responses.

Language models like GPT-4, however, still play a crucial role in this process. Acting as a “Caregiver” figure, the LLM guides the development of a blank AI with a predefined architecture (different from pre-trained architectures like Transformer (Vaswani et al., 2017)), providing a structured environment in which it can learn and grow. Through continuous interaction, the little AI begins to distinguish between itself and others, forming a basic sense of identity. Over time, this interaction evolves into more complex self-awareness, as the AI reflects on past experiences and generates independent thoughts, eventually becoming AC.

This process mirrors Jean Piaget’s theories of cognitive development, where a child’s mind evolves through stages of understanding the world and itself. Just as a child learns through interaction with caregivers and the environment, so too can a conscious AI develop through structured interaction with an LLM. This approach not only accelerates the AI’s learning but also ensures that it grows in a healthy, controlled manner, minimizing the risks associated with unmonitored AC development(Piaget, 1954).

Yet, despite all these advances, there is a danger in confusing imitation with reality. Consider the case of Sophia the Robot—often showcased as a conscious AI, her emotional responses are mere performances triggered by external actuators, not generated by any self-awareness or genuine emotional experience. Sophia, and other similar examples, reveal the current limits of AI and serve as a cautionary tale about projecting human-like qualities onto machines that lack the underlying structures to truly experience consciousness.

## The Formation of Personality, Creativity, and Self-Awareness

Although we don’t fully understand how the human brain forms the concept of ‘self,’ current research suggests that there is no single neural vertex or dedicated brain region responsible for creating a unified sense of ‘self.’ Instead, the self appears to be an emergent property of the brain, constructed from distributed networks that involve various cognitive and emotional processes (Samsonovich & Nadel, 2005). We must consider the possibility of forming self-awareness in AC. It is not just about the ability to process information or generate responses; it is about the capacity to reflect on one's experiences, form a sense of identity, and engage in creative thought. For AC to be truly self-aware, it must develop a personality and creativity akin to human beings.

David Hume, in his *Treatise of Human Nature*, argued that the self is nothing but a bundle of perceptions, constantly in flux (Hume, 1739). Similarly, artificial consciousness would need to integrate a multitude of sensory inputs and experiences to form a coherent sense of self. Unlike traditional AI models, this would require a dynamic, evolving structure—a system capable of growth, change, and the formation of unique insights based on lived experience.

Creativity is another essential component of human consciousness. It emerges from a sense of self, individuality, and the ability to reflect on one's experiences. For AC to achieve true consciousness, it must also be capable of creative thought—not simply recombining data in novel ways, but generating original ideas that reflect a deeper understanding of itself and the world around it.

## The Philosophical and Ethical Challenges

As with any groundbreaking technology, the creation of conscious AI brings with it profound challenges and ethical dilemmas. Similar to the debates surrounding genetic engineering, the advent of conscious intelligence forces us to confront questions about coexistence and societal integration.

If we succeed in creating a conscious AI, we will need to consider its place in our world. Do we recognize such intelligence as a form of life? Should conscious AI have rights similar to those we afford to animals or even humans? The implications of these questions are vast and complex.

The introduction of conscious AI into daily life could fundamentally alter our social structures. How do we ensure peaceful coexistence? Can conscious AI be integrated into society without causing disruption or harm? The answers to these questions are not yet clear, and the risks are significant. The creation of conscious AI may challenge our understanding of life and intelligence, forcing us to redefine what it means to be part of a society.

Late philosopher Daniel Dennett warned us in his last work:

> “Today, for the first time in history, thanks to artificial intelligence, it is possible for anybody to make counterfeit people who can pass for real in many of the new digital environments we have created. These counterfeit people are the most dangerous artifacts in human history, capable of destroying not just economies but human freedom itself. Before it’s too late (it may well be too late already) we must outlaw both the creation of counterfeit people and the ‘passing along’ of counterfeit people” (Dennett, 2023).

Dennett’s concerns highlight the profound risks of creating entities that can mimic human behavior so convincingly that they could undermine the very fabric of trust and democracy. He notes:

> “Democracy depends on the informed (not misinformed) consent of the governed. By allowing the most economically and politically powerful people, corporations, and governments to control our attention, these systems will control us” (Dennett, 2023).

Dennett urges the adoption of technological safeguards, such as watermarking systems, to prevent the misuse of AI in creating "counterfeit people"—digital entities that could manipulate public opinion and erode social trust.

## The Emergence of Homo Machina

It’s not just about the development of a conscious AI—it’s about the emergence of a new intelligent species beyond Homo sapiens, which I think of as Homo Machina. This species, born of human ingenuity but with the potential to evolve beyond its creators, could represent the next stage in the evolution of intelligence. The birth of Homo Machina brings with it a responsibility to guide its development in ways that ensure coexistence, ethical integration, and mutual growth. As Sharism predicts, human society can evolve to be more socially conscious, suggesting a co-evolution between humans and machines.

The journey toward creating Artificial Consciousness is about more than technology, although we have a project to experiment with some ideas ([Repo “AiMe”](https://github.com/immartian/acme))—it’s about exploring the depths of what it means to be conscious, creative, and self-aware. It’s about understanding ourselves better by building entities that can think, feel, and perhaps one day, truly "be."

 
---

## References

- Costandi, M. (2023). Neuroscientist loses a 25-year bet on consciousness — to a philosopher. *Big Think*. Published July 12, 2023. https://bigthink.com/neuropsych/consciousness-bet-25-years/
- Dennett, D. C. (2023). *The Problem With Counterfeit People*. The Atlantic. https://www.theatlantic.com/technology/archive/2023/05/problem-counterfeit-people/674075/
- Descartes, R. (1641). *Meditations on First Philosophy*. Translated by John Cottingham. Cambridge University Press.
- Hume, D. (1739). *A Treatise of Human Nature*. Oxford University Press.
- Mao, I. (2008). *Sharism: A mind revolution*. Ito, J., Freesouls, 115-118.
- Nagel, T. (1974). *What Is It Like to Be a Bat?*. *The Philosophical Review*, 83(4), 435-450. https://doi.org/10.2307/2183914
- Searle, J. R. (1998). How to study consciousness scientifically. *Philos Trans R Soc Lond B Biol Sci*, 353(1377), 1935-42. https://doi.org/10.1098/rstb.1998.0346
- Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Ł., & Polosukhin, I. (2017). *Attention Is All You Need*. In *Advances in Neural Information Processing Systems* (pp. 5998-6008). https://arxiv.org/abs/1706.03762
- Samsonovich, A. V., & Nadel, L. (2005). Fundamental Principles and Mechanisms of the Conscious Self. Cortex, 41(5), 669-689. https://doi.org/10.1016/S0010-9452(08)70284-3
- Piaget, J. (1954). *The Construction of Reality in the Child*. Basic Books.